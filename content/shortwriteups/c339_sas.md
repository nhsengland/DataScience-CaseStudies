---
layout: base
title: Creating a Generic Adversarial Attack for any Synthetic Dataset 
permalink: c339_sas.html
---

# {{page.title}}
> | "Can the privacy of a generated dataset be assessed through downstream adversarial attacks to highlight the risk of reidentificiation "   

<p align="center">
    <img src="assets/img/c339fig1.png" alt=""  width="800"/>
</p>
<p align="left">
    <em>Figure 1: Attack diagrams for the currently incorporated scenarios.  Scenario 1: Access to the synthetic dataset and a description of the generative modelâ€™s architecture and training procedure.  Scenario 2: Access to a black box model that can provide unlimited synthetic data, with data realistic of the training distribution gathered by the attacker, which may be an example synthetic dataset released by the researchers.</em>
</p>

An extensible code was developed to apply a suite of adversarial attacks to synthetically generated single table tabular data in order to assess the likely success of attacks and act as a privacy indicator for the dataset.  Using this information then informs the generation and information governance process to ensure the safety of our data. 

## Results 



| Output | Link | 
| ---- | ---- |
| Open Source Code & Documentation | [Github]() |
| Case Study | Awaiting Sign-Off |
| Technical report | [Here]() |

||||
|:-|:-|:-|
|<img src="assets/img/simulation_badge_S.png" alt  width="80"/>|<img src="assets/img/Synthetic.png" alt  width="80"/>|<img src="assets/img/machine_learning_badge_S.png" alt  width="80"/>|
